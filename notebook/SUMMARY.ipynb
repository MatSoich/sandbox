{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import codecs\n",
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "from typing import Dict, List, Any\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "from multiprocessing import Process, Array\n",
    "from enum import IntEnum\n",
    "\n",
    "from xbrl_reader import Inf, SchemaElement, read_lines, ReadSchema, ReadLabel, parseElement, read_company_dic, getAttribs, label_role, verboseLabel_role\n",
    "from xbrl_reader import readCalcSub, readCalcArcs, period_names\n",
    "from download import company_dic\n",
    "from xbrl_table import all_account_ids, filing_date_account_ids\n",
    "from stats import write_calc_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "class ContextType(IntEnum):\n",
    "    FilingDate = 0  # 提出日時点\n",
    "    Instant = 1     # 会計終了時点\n",
    "    Duration = 2    # 会計期間\n",
    "\n",
    "\n",
    "base_annual_context_names = [\n",
    "    \"CurrentYearInstant\", \"CurrentYearDuration\",\n",
    "    \"Prior1YearInstant\", \"Prior1YearDuration\",\n",
    "]\n",
    "\n",
    "# base_quarterly_context_names = [\n",
    "#     \"CurrentQuarterInstant\", \"CurrentYTDDuration\", \"CurrentQuarterDuration\",\n",
    "#     \"Prior1QuarterInstant\", \"Prior1YTDDuration\", \"Prior1QuarterDuration\",\n",
    "# ]\n",
    "\n",
    "annual_context_names = base_annual_context_names + \\\n",
    "    [x + \"_NonConsolidatedMember\" for x in base_annual_context_names]\n",
    "# quarterly_context_names = base_quarterly_context_names + [ x + \"_NonConsolidatedMember\" for x in base_quarterly_context_names ]\n",
    "quarterly_context_names = [\n",
    "    \"CurrentQuarterInstant\",  # 当四半期会計期間連結時点,\n",
    "    \"CurrentYTDDuration\",    # 当四半期累計期間連結期間,\n",
    "    \"Prior1YearInstant\",     # 前期連結時点\n",
    "    \"Prior1YTDDuration\",     # 前年度同四半期累計期間連結期間\n",
    "]\n",
    "\n",
    "context_names = [\"FilingDateInstant\"] + \\\n",
    "    annual_context_names + quarterly_context_names\n",
    "\n",
    "# \"Prior1YearInstant_NonConsolidatedMember\", \"Prior1YearDuration_NonConsolidatedMember\",\n",
    "# \"Prior1QuarterInstant_NonConsolidatedMember\", \"Prior1YTDDuration_NonConsolidatedMember\", \"Prior1QuarterDuration_NonConsolidatedMember\",\n",
    "# \"Prior1YearInstant_NonConsolidatedMember\", \"Prior1YearDuration_NonConsolidatedMember\",\n",
    "# \"Prior1QuarterInstant_NonConsolidatedMember\", \"Prior1YTDDuration_NonConsolidatedMember\", \"Prior1QuarterDuration_NonConsolidatedMember\",\n",
    "# \"InterimInstant\", \"InterimInstant_NonConsolidatedMember\", \"InterimDuration\", \"InterimDuration_NonConsolidatedMember\"\n",
    "\n",
    "fixed_ids = False\n",
    "account_dics = [{}, {}, {}]\n",
    "ns_xsd_dic = {}\n",
    "verbose_label_dic = {}\n",
    "\n",
    "root_dir = os.path.dirname(os.path.dirname(\n",
    "    #os.path.abspath(__file__))).replace('\\\\', '/')\n",
    "    os.path.abspath('SUMMARY.ipynb'))).replace('\\\\', '/')\n",
    "data_path = root_dir + '/python/data'\n",
    "extract_path = root_dir + '/zip/extract'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadAllSchema():\n",
    "    \"\"\"スキーマと名称リンクと計算リンクのファイルを読む。\n",
    "    \"\"\"\n",
    "    inf = Inf()\n",
    "\n",
    "    xsd_label_files = [\n",
    "        [\"jpcrp_cor\", \"jpcrp/2019-11-01/jpcrp_cor_2019-11-01.xsd\",\n",
    "            \"jpcrp/2019-11-01/label/jpcrp_2019-11-01_lab.xml\"],\n",
    "        [\"jppfs_cor\", \"jppfs/2019-11-01/jppfs_cor_2019-11-01.xsd\",\n",
    "            \"jppfs/2019-11-01/label/jppfs_2019-11-01_lab.xml\"],\n",
    "        [\"jpdei_cor\", \"jpdei/2013-08-31/jpdei_cor_2013-08-31.xsd\",\n",
    "            \"jpdei/2013-08-31/label/jpdei_2013-08-31_lab.xml\"],\n",
    "        [\"jpigp_cor\", \"jpigp/2019-11-01/jpigp_cor_2019-11-01.xsd\",\n",
    "            \"jpigp/2019-11-01/label/jpigp_2019-11-01_lab.xml\"]\n",
    "    ]\n",
    "\n",
    "    for prefix, xsd_file, lable_file in xsd_label_files:\n",
    "        print('EDINETタクソノミの読み込み中・・・ : %s' % prefix)\n",
    "\n",
    "        xsd_path = \"%s/data/EDINET/taxonomy/2019-11-01/taxonomy/%s\" % (\n",
    "            root_dir, xsd_file)\n",
    "\n",
    "        xsd_dic: Dict[str, SchemaElement] = {}\n",
    "\n",
    "        xsd_tree = ET.parse(xsd_path)\n",
    "        xsd_root = xsd_tree.getroot()\n",
    "\n",
    "        # スキーマファイルの内容を読む。\n",
    "        ReadSchema(inf, False, xsd_path, xsd_root, xsd_dic)\n",
    "\n",
    "        label_path = \"%s/data/EDINET/taxonomy/2019-11-01/taxonomy/%s\" % (\n",
    "            root_dir, lable_file)\n",
    "        label_tree = ET.parse(label_path)\n",
    "        label_root = label_tree.getroot()\n",
    "\n",
    "        resource_dic = {}\n",
    "        loc_dic = {}\n",
    "        # 名称リンクファイルの内容を読む。\n",
    "        ReadLabel(label_root, xsd_dic, loc_dic, resource_dic)\n",
    "\n",
    "        if prefix in [\"jppfs_cor\", \"jpigp_cor\"]:\n",
    "            xsd_base = os.path.dirname(xsd_path)\n",
    "\n",
    "            # フォルダーの下の計算リンクファイルに対し\n",
    "            for xml_path_obj in Path(xsd_base).glob('r/**/*_cal_*.xml'):\n",
    "                xml_path = str(xml_path_obj).replace('\\\\', '/')\n",
    "                locs = {}\n",
    "                arcs = []\n",
    "\n",
    "                # 計算リンクファイルの内容を読む。\n",
    "                readCalcSub(inf, ET.parse(xml_path).getroot(),\n",
    "                            xsd_dic, locs, arcs)\n",
    "\n",
    "                # 計算リンクの計算関係を得る。\n",
    "                readCalcArcs(xsd_dic, locs, arcs)\n",
    "\n",
    "        ns_xsd_dic[prefix] = xsd_dic\n",
    "\n",
    "        for ele in xsd_dic.values():\n",
    "            if ele.verbose_label in verbose_label_dic:\n",
    "                # 冗長ラベルの辞書にある場合\n",
    "\n",
    "                # 辞書にあるものと同じはず\n",
    "                assert verbose_label_dic[ele.verbose_label] == ele\n",
    "            else:\n",
    "                # 冗長ラベルの辞書にない場合\n",
    "\n",
    "                # 辞書に追加する。\n",
    "                verbose_label_dic[ele.verbose_label] = ele\n",
    "\n",
    "    # assert xsd_dics[uri] == xsd_dic\n",
    "\n",
    "\n",
    "def get_context_type(context_name: str):\n",
    "    \"\"\"コンテストのタイプを返す。\n",
    "\n",
    "    * 0: 提出日時点\n",
    "    * 1: 会計末時点\n",
    "    * 2: 会計期間\n",
    "\n",
    "    Args:\n",
    "        context_name(str) : コンテスト名\n",
    "\n",
    "    Returns:\n",
    "        int : コンテストのタイプ\n",
    "    \"\"\"\n",
    "    k = context_name.rfind(\"_NonConsolidatedMember\")\n",
    "    if k != -1:\n",
    "        context_name = context_name[: k]\n",
    "\n",
    "    if context_name == \"FilingDateInstant\":\n",
    "        # 提出日時点の場合\n",
    "\n",
    "        return ContextType.FilingDate\n",
    "    elif context_name.endswith(\"Instant\"):\n",
    "        # 会計末時点の場合\n",
    "\n",
    "        return ContextType.Instant\n",
    "    else:\n",
    "        assert context_name.endswith(\"Duration\")\n",
    "        # 会計期間の場合\n",
    "\n",
    "        return ContextType.Duration\n",
    "\n",
    "\n",
    "def collect_values(edinetCode: str, values, major_context_names, stats, el: ET.Element):\n",
    "    \"\"\"XBRLファイルの内容を読む。\n",
    "    \"\"\"\n",
    "    id, uri, tag_name, text = parseElement(el)\n",
    "\n",
    "    if tag_name == \"xbrl\":\n",
    "        for child in el:\n",
    "            collect_values(edinetCode, values,\n",
    "                           major_context_names, stats, child)\n",
    "        return\n",
    "\n",
    "    if text is None:\n",
    "        return\n",
    "\n",
    "    context_ref = el.get(\"contextRef\")\n",
    "    if context_ref is None or not context_ref in context_names:\n",
    "        return\n",
    "\n",
    "    # 名前空間を得る。\n",
    "    ns = uri.split('/')[-1]\n",
    "\n",
    "    ele = None\n",
    "    if ns in ns_xsd_dic:\n",
    "        # 名前空間に対応するスキーマの辞書がある場合\n",
    "\n",
    "        xsd_dic = ns_xsd_dic[ns]\n",
    "        if tag_name in xsd_dic:\n",
    "            # タグ名に対応する要素がスキーマの辞書にある場合\n",
    "\n",
    "            # タグ名に対応する要素を得る。\n",
    "            ele = xsd_dic[tag_name]\n",
    "            if ele.type in [\"textBlockItemType\"]:\n",
    "                # テキストブロックの場合\n",
    "\n",
    "                return\n",
    "\n",
    "    if ele is None:\n",
    "        return\n",
    "\n",
    "    id = \"%s:%s\" % (ns, tag_name)\n",
    "\n",
    "    # コンテストのタイプを得る。\n",
    "    context_type = get_context_type(context_ref)\n",
    "\n",
    "    # コンテストのタイプに対応する項目の辞書を得る。\n",
    "    account_dic = account_dics[context_type]\n",
    "\n",
    "    if context_ref in major_context_names:\n",
    "        # 集計対象のコンテストの場合\n",
    "\n",
    "        if fixed_ids:\n",
    "            # 項目が固定の場合\n",
    "\n",
    "            if not id in account_dic and '（IFRS）' in ele.verbose_label:\n",
    "                # 集計対象のIDでなく、冗長ラベルに'（IFRS）'が含まれる場合\n",
    "\n",
    "                # 冗長ラベルから'（IFRS）'を取り除く。\n",
    "                verbose_label = ele.verbose_label.replace('（IFRS）', '')\n",
    "\n",
    "                if verbose_label in verbose_label_dic:\n",
    "                    # 冗長ラベルの辞書にある場合\n",
    "\n",
    "                    # 'Japan GAAP'の要素で代用する。\n",
    "                    ele = verbose_label_dic[verbose_label]\n",
    "                    id = ele.id.replace('_cor_', '_cor:')\n",
    "\n",
    "        if id in account_dic:\n",
    "            # 集計対象のIDの場合\n",
    "\n",
    "            major_idx = major_context_names.index(context_ref)\n",
    "\n",
    "            if ele.type == \"stringItemType\":\n",
    "                # 文字列の場合\n",
    "\n",
    "                # エスケープ処理をする。\n",
    "                text = json.dumps(text, ensure_ascii=False)\n",
    "\n",
    "            values[major_idx][account_dic[id]] = text\n",
    "\n",
    "    if context_type != ContextType.FilingDate and ele.type in [\"stringItemType\", \"dateItemType\", \"booleanItemType\"]:\n",
    "        # 提出日時点以外のコンテストで、型が数値でない場合\n",
    "\n",
    "        return\n",
    "\n",
    "    idx = context_names.index(context_ref)\n",
    "    stats[idx][id] += 1\n",
    "\n",
    "\n",
    "def context_display_name(context_ref: str):\n",
    "    \"\"\"コンテストの日本語名を返す。\n",
    "\n",
    "    Args:\n",
    "        context_ref(str): コンテスト名\n",
    "\n",
    "    Returns:\n",
    "        str : コンテストの日本語名\n",
    "    \"\"\"\n",
    "    if context_ref.endswith(\"_NonConsolidatedMember\"):\n",
    "        # 個別決算の場合\n",
    "\n",
    "        name = context_ref.replace(\"_NonConsolidatedMember\", \"\")\n",
    "        return period_names[name].replace(\"連結\", \"個別\")\n",
    "    else:\n",
    "        # 連結決算の場合\n",
    "\n",
    "        return period_names[context_ref]\n",
    "\n",
    "\n",
    "def make_titles(context_type: str) -> List[str]:\n",
    "    \"\"\"CSVファイルの先頭行に表示する項目名のリストを返す。\n",
    "\n",
    "    Args:\n",
    "        context_type(str)   : コンテスト名\n",
    "\n",
    "    Returns:\n",
    "        List[str]: 項目名のリスト\n",
    "    \"\"\"\n",
    "    account_ids = all_account_ids[context_type]\n",
    "    account_dic = account_dics[context_type]\n",
    "    assert len(account_ids) == len(set(account_ids))\n",
    "\n",
    "    # 項目名のリスト\n",
    "    titles = [\"\"] * len(account_ids)\n",
    "\n",
    "    # スキーマの要素のリスト\n",
    "    eles = [None] * len(account_ids)\n",
    "\n",
    "    for id_idx, id in enumerate(account_ids):\n",
    "        assert not id in account_dic\n",
    "        account_dic[id] = id_idx\n",
    "\n",
    "        # 名前空間とタグ名を得る。\n",
    "        ns, tag_name = id.split(':')\n",
    "\n",
    "        # 名前空間に対応するスキーマの辞書を得る。\n",
    "        assert ns in ns_xsd_dic\n",
    "        xsd_dic = ns_xsd_dic[ns]\n",
    "\n",
    "        # タグ名に対応する要素を得る。\n",
    "        assert tag_name in xsd_dic\n",
    "        ele = xsd_dic[tag_name]\n",
    "\n",
    "        if ele.label in titles:\n",
    "            # すでに同じラベルがある場合\n",
    "\n",
    "            # 重複するラベルの位置\n",
    "            i = titles.index(ele.label)\n",
    "\n",
    "            # 冗長ラベルが重複しないはず。\n",
    "            assert ele.verbose_label != eles[i].verbose_label\n",
    "\n",
    "            # 冗長ラベルを使う。\n",
    "            titles[i] = eles[i].verbose_label\n",
    "            label = ele.verbose_label\n",
    "        else:\n",
    "            # 同じラベルがない場合\n",
    "\n",
    "            label = ele.label\n",
    "\n",
    "        assert not label in titles\n",
    "        assert not \",\" in label\n",
    "\n",
    "        eles[id_idx] = ele\n",
    "        titles[id_idx] = label\n",
    "\n",
    "    return titles\n",
    "\n",
    "\n",
    "def get_xbrl_root(cpu_count, cpu_id):\n",
    "    \"\"\"CPUごとのサブプロセスの処理\n",
    "\n",
    "    EDINETコードをCPU数で割った余りがCPU-IDに等しければ処理をする。\n",
    "\n",
    "    Args:\n",
    "        cpu_count(int): CPU数\n",
    "        cpu_id   (int): CPU-ID (0, ..., CPU数 - 1)\n",
    "\n",
    "    Returns:\n",
    "        XBRLファイルの名前とパースしたルート\n",
    "    \"\"\"\n",
    "    for zip_path_obj in Path(extract_path).glob(\"**/E*.zip\"):\n",
    "        zip_path = str(zip_path_obj)\n",
    "\n",
    "        edinetCode = os.path.basename(zip_path).split('.')[0]\n",
    "        assert edinetCode[0] == 'E'\n",
    "        if int(edinetCode[1:]) % cpu_count != cpu_id:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # 抽出先のZIPファイルを読み込みモードで開く。\n",
    "            with zipfile.ZipFile(zip_path) as zf:\n",
    "\n",
    "                # 期末日とファイル名のペアのリスト\n",
    "                enddate_filename = [[x.split('_')[2], x]\n",
    "                                    for x in zf.namelist()]\n",
    "\n",
    "                # 期末日の順にソートする。\n",
    "                enddate_filename = sorted(enddate_filename, key=lambda x: x[0])\n",
    "\n",
    "                # ZIPファイル内のXBRLファイルに対し\n",
    "                for _, xbrl_file in enddate_filename:\n",
    "\n",
    "                    # XBRLファイルのデータを読む。\n",
    "                    with zf.open(xbrl_file) as f:\n",
    "                        xml_bin = f.read()\n",
    "\n",
    "                    # バイナリデータをutf-8テキストとしてデコードする。\n",
    "                    xml_text = xml_bin.decode('utf-8')\n",
    "\n",
    "                    # XBRLファイルのテキストをパースする。\n",
    "                    root = ET.fromstring(xml_text)\n",
    "\n",
    "                    yield xbrl_file, root\n",
    "\n",
    "        except zipfile.BadZipFile:\n",
    "            print(\"\\nBadZipFile : %s\\n\" % zip_path)\n",
    "            continue\n",
    "\n",
    "\n",
    "def read_stats_json():\n",
    "    \"\"\"出現頻度ののJSONファイルを読む。\n",
    "    \"\"\"\n",
    "    global all_account_ids, filing_date_account_ids\n",
    "\n",
    "    # 出現頻度のJSONファイルを読む。\n",
    "    # 前回の実行で作ったstats.jsonをstats-master.jsonにリネームしておく。\n",
    "    stats_master_path = '%s/stats-master.json' % data_path\n",
    "    if not os.path.exists(stats_master_path):\n",
    "        # stats-master.jsonがない場合\n",
    "\n",
    "        stats_path = '%s/stats.json' % data_path\n",
    "        if os.path.exists(stats_path):\n",
    "            # stats.jsonがある場合\n",
    "\n",
    "            print('\\n    %sを、stats-master.jsonにリネームしてから実行してください。' % stats_path)\n",
    "\n",
    "        else:\n",
    "            # stats.jsonがない場合\n",
    "\n",
    "            print('\\n    %sがありません。\\n' % stats_master_path)\n",
    "            print('    以下の手順を実行してください。\\n')\n",
    "            print('    1. 引数にfixをつけて実行します。\\n')\n",
    "            print('        python summary.py fix\\n')\n",
    "            print('    2. %sを、stats-master.jsonにリネームします。' % stats_path)\n",
    "\n",
    "        sys.exit()\n",
    "\n",
    "    with codecs.open(stats_master_path, 'r', 'utf-8') as f:\n",
    "        stats_json = json.load(f)\n",
    "\n",
    "    # コンテストのタイプごとに使用する項目のsetのリスト\n",
    "    all_account_ids = [set(), set(), set()]\n",
    "\n",
    "    # 報告書の種類ごとに\n",
    "    for report_name, report_json in stats_json.items():\n",
    "\n",
    "        # 会計基準ごとに\n",
    "        for accounting_standard, accounting_json in report_json.items():\n",
    "\n",
    "            # コンテキストごとに\n",
    "            for context_name, context_json in accounting_json.items():\n",
    "                if context_name.startswith('Prior'):\n",
    "                    # 前期、前々期などの場合\n",
    "\n",
    "                    continue\n",
    "\n",
    "                # コンテストのタイプごとに使用する項目のset\n",
    "                ids = all_account_ids[get_context_type(context_name)]\n",
    "                valid_cnt = 0\n",
    "\n",
    "                # 項目ごとに\n",
    "                for id, v in context_json.items():\n",
    "                    if v[3] in [\"stringItemType\", \"dateItemType\"]:\n",
    "                        # 文字列か日付の場合\n",
    "\n",
    "                        if id != \"jpdei_cor:AccountingStandardsDEI\":\n",
    "                            # 会計基準でない場合\n",
    "\n",
    "                            continue\n",
    "\n",
    "                    # booleanItemType, nonNegativeIntegerItemType, monetaryItemType, perShareItemType, percentItemType, decimalItemType, sharesItemType\n",
    "\n",
    "                    # 使用する項目のsetに追加する。\n",
    "                    ids.add(id)\n",
    "\n",
    "                    valid_cnt += 1\n",
    "                    if valid_cnt == 200:\n",
    "                        # 出現頻度の上位200個の項目のみ使う。\n",
    "\n",
    "                        break\n",
    "\n",
    "    # setをlistに変換する。\n",
    "    all_account_ids = [list(x) for x in all_account_ids]\n",
    "\n",
    "    # 提出日時点\n",
    "    filing_date_account_ids = all_account_ids[0]\n",
    "\n",
    "\n",
    "def make_summary(fixed_ids_arg, cpu_count, cpu_id, ns_xsd_dic_arg, verbose_label_dic_arg, all_account_ids_arg, filing_date_account_ids_arg):\n",
    "    \"\"\"CPUごとのサブプロセスの処理\n",
    "\n",
    "    EDINETコードをCPU数で割った余りがCPU-IDに等しければ処理をする。\n",
    "\n",
    "    Args:\n",
    "        cpu_count(int) : CPU数\n",
    "        cpu_id   (int) : CPU-ID (0, ..., CPU数 - 1)\n",
    "        ns_xsd_dic_arg : スキーマの辞書\n",
    "    \"\"\"\n",
    "\n",
    "    global fixed_ids, ns_xsd_dic, verbose_label_dic, all_account_ids, filing_date_account_ids\n",
    "\n",
    "    fixed_ids = fixed_ids_arg\n",
    "    for key, dict in ns_xsd_dic_arg.items():\n",
    "        ns_xsd_dic[key] = dict\n",
    "\n",
    "    verbose_label_dic = verbose_label_dic_arg.copy()\n",
    "    all_account_ids = all_account_ids_arg\n",
    "    filing_date_account_ids = filing_date_account_ids_arg\n",
    "\n",
    "    # ns_xsd_dic = ns_xsd_dic_arg\n",
    "    print(\"start subprocess cpu-id:%d\" % cpu_id)\n",
    "\n",
    "    csv_f = [None, None, None]\n",
    "    for context_type in range(3):\n",
    "        csv_f[context_type] = codecs.open(\n",
    "            \"%s/summary-%d-%d.csv\" % (data_path, context_type, cpu_id), 'w', 'utf-8')\n",
    "\n",
    "        # CSVファイルの先頭行に表示する項目名のリスト\n",
    "        titles = make_titles(context_type)\n",
    "        if context_type == 0:\n",
    "            # 提出日時点の場合\n",
    "\n",
    "            csv_f[context_type].write(\n",
    "                \"EDINETコード,会計期間終了日,報告書略号,%s\\n\" % \",\".join(titles))\n",
    "        else:\n",
    "            # 会計末時点か会計期間の場合\n",
    "\n",
    "            csv_f[context_type].write(\n",
    "                \"EDINETコード,会計期間終了日,報告書略号,コンテキスト,%s\\n\" % \",\".join(titles))\n",
    "\n",
    "    annual_account_stats = {}\n",
    "    quarterly_account_stats = {}\n",
    "\n",
    "    cnt = 0\n",
    "\n",
    "    # XBRLファイルの名前とパースしたルートに対し\n",
    "    for xbrl_file_name, root in get_xbrl_root(cpu_count, cpu_id):\n",
    "\n",
    "        # 報告書インスタンス作成ガイドライン\n",
    "        #  4-2-4 XBRLインスタンスファイル XBRLインスタンスファイルの命名規約\n",
    "        # jp{府令略号}{様式番号}-{報告書略号}-{報告書連番(3桁)}\n",
    "        # {EDINETコード又はファンドコード}-{追番(3桁)}\n",
    "        # {報告対象期間期末日|報告義務発生日}\n",
    "        # {報告書提出回数(2桁)}\n",
    "        # {報告書提出日}.xbrl\n",
    "\n",
    "        v1 = xbrl_file_name.split('_')\n",
    "        if v1[3] != \"01\":\n",
    "            # 訂正の場合\n",
    "\n",
    "            continue\n",
    "\n",
    "        edinetCode = v1[1].split('-')[0]\n",
    "        if not edinetCode in company_dic:\n",
    "            continue\n",
    "\n",
    "        end_date = v1[2]\n",
    "\n",
    "        company = company_dic[edinetCode]\n",
    "        if company['category_name_jp'] in [\"保険業\", \"その他金融業\", \"証券、商品先物取引業\", \"銀行業\"]:\n",
    "            # 銀行・証券・保険などの金融業は会計が特殊なのでスキップ\n",
    "\n",
    "            continue\n",
    "\n",
    "        v2 = v1[0].split('-')\n",
    "        repo = v2[1]\n",
    "        if repo == \"asr\":\n",
    "            major_context_names = [\"FilingDateInstant\"] + annual_context_names\n",
    "\n",
    "        elif repo in [\"q1r\", \"q2r\", \"q3r\", \"q4r\"]:\n",
    "            major_context_names = [\n",
    "                \"FilingDateInstant\"] + quarterly_context_names\n",
    "\n",
    "        elif repo == \"ssr\" or repo == \"q5r\":\n",
    "            continue\n",
    "        else:\n",
    "            print(\"unknown report\", repo, xbrl_file_name)\n",
    "            continue\n",
    "\n",
    "        stats_local = [Counter() for _ in context_names]\n",
    "\n",
    "        values = [[\"\"] * len(all_account_ids[get_context_type(x)])\n",
    "                  for x in major_context_names]\n",
    "\n",
    "        # XBRLファイルの内容を読む。\n",
    "        collect_values(edinetCode, values,\n",
    "                       major_context_names, stats_local, root)\n",
    "\n",
    "        # 会計基準の位置\n",
    "        accounting_standards_idx = filing_date_account_ids.index(\n",
    "            \"jpdei_cor:AccountingStandardsDEI\")\n",
    "\n",
    "        # 提出日時点の位置\n",
    "        filing_date_instant_idx = major_context_names.index(\n",
    "            \"FilingDateInstant\")\n",
    "        assert filing_date_instant_idx == 0\n",
    "\n",
    "        # 会計基準\n",
    "        accounting_standard = values[filing_date_instant_idx][accounting_standards_idx]\n",
    "        assert accounting_standard != \"\"\n",
    "\n",
    "        if repo == \"asr\":\n",
    "            # 有価証券報告書の場合\n",
    "\n",
    "            account_stats = annual_account_stats\n",
    "        else:\n",
    "            # 四半期報告書の場合\n",
    "\n",
    "            account_stats = quarterly_account_stats\n",
    "\n",
    "        if accounting_standard in account_stats:\n",
    "            # 会計基準がすでにある場合\n",
    "\n",
    "            stats_sum = account_stats[accounting_standard]\n",
    "        else:\n",
    "            # 初めての会計基準の場合\n",
    "\n",
    "            stats_sum = [Counter() for _ in context_names]\n",
    "            account_stats[accounting_standard] = stats_sum\n",
    "\n",
    "        for tmp_sum, tmp in zip(stats_sum, stats_local):\n",
    "            for s, c in tmp.items():\n",
    "                tmp_sum[s] += c\n",
    "\n",
    "        # 主要なコンテキストの種類ごとに\n",
    "        for idx, context_name in enumerate(major_context_names):\n",
    "            context_type = get_context_type(context_name)\n",
    "\n",
    "            if context_type == 0:\n",
    "                csv_f[context_type].write(\"%s,%s,%s,%s\\n\" % (\n",
    "                    edinetCode, end_date, repo, \",\".join(values[idx])))\n",
    "            else:\n",
    "                csv_f[context_type].write(\"%s,%s,%s,%s,%s\\n\" % (\n",
    "                    edinetCode, end_date, repo, context_display_name(context_name), \",\".join(values[idx])))\n",
    "\n",
    "        cnt += 1\n",
    "        if cnt % 500 == 0:\n",
    "            print(\"cpu-id:%d count:%d\" % (cpu_id, cnt))\n",
    "\n",
    "    # 報告書の種類ごとに\n",
    "    for report_idx, account_stats in enumerate([annual_account_stats, quarterly_account_stats]):\n",
    "\n",
    "        # statsをpickleに書く。\n",
    "        stats_path = '%s/stats-%d-%d.pickle' % (data_path, report_idx, cpu_id)\n",
    "        with open(stats_path, 'wb') as f:\n",
    "            pickle.dump(account_stats, f)\n",
    "\n",
    "    for f in csv_f:\n",
    "        f.close()\n",
    "\n",
    "    print(\"end subprocess  cpu-id:%d  total:%d\" % (cpu_id, cnt))\n",
    "\n",
    "\n",
    "def concatenate_stats(cpu_count):\n",
    "    \"\"\"サブプロセスで作ったstatsを１つにまとめる。\n",
    "\n",
    "    Args:\n",
    "        cpu_count(int): CPU数\n",
    "    \"\"\"\n",
    "    stats_f = codecs.open(\"%s/stats.txt\" % data_path, 'w', 'utf-8')\n",
    "\n",
    "    annual_account_stats = {}\n",
    "    quarterly_account_stats = {}\n",
    "\n",
    "    # 出現頻度のJSON\n",
    "    stats_json = {}\n",
    "\n",
    "    # 報告書の種類ごとに\n",
    "    for report_idx, report_name in enumerate([\"有価証券報告書\", \"四半期報告書\"]):\n",
    "\n",
    "        account_stats = annual_account_stats if report_idx == 0 else quarterly_account_stats\n",
    "\n",
    "        # CPU-IDに対し\n",
    "        for cpu_id in range(cpu_count):\n",
    "\n",
    "            # statsのpickleを読む。\n",
    "            stats_path = \"%s/stats-%d-%d.pickle\" % (\n",
    "                data_path, report_idx, cpu_id)\n",
    "            with open(stats_path, 'rb') as f:\n",
    "                stats_dic_tmp = pickle.load(f)\n",
    "\n",
    "            os.remove(stats_path)\n",
    "\n",
    "            # 会計基準ごとに\n",
    "            for accounting_standard, stats_tmp in stats_dic_tmp.items():\n",
    "\n",
    "                if accounting_standard in account_stats:\n",
    "                    stats_sum = account_stats[accounting_standard]\n",
    "                else:\n",
    "                    stats_sum = [Counter() for _ in context_names]\n",
    "                    account_stats[accounting_standard] = stats_sum\n",
    "\n",
    "                # コンテキストの種類ごとに\n",
    "                for idx, context_name in enumerate(context_names):\n",
    "\n",
    "                    # 項目ごとに\n",
    "                    for name, cnt in stats_tmp[idx].items():\n",
    "                        stats_sum[idx][name] += cnt\n",
    "\n",
    "        stats_f.write(\"\\n%s\\n報告書      : %s\\n%s\\n\" %\n",
    "                      ('-'*80, report_name, '-'*80))\n",
    "\n",
    "        # 報告書の種類ごとの出現頻度のJSON\n",
    "        report_json = {}\n",
    "        stats_json[report_name] = report_json\n",
    "\n",
    "        # 会計基準ごとに\n",
    "        for accounting_standard, stats in account_stats.items():\n",
    "\n",
    "            # 会計基準ごとの出現頻度のJSON\n",
    "            accounting_json = {}\n",
    "            report_json[accounting_standard] = accounting_json\n",
    "\n",
    "            stats_f.write(\"\\n%s\\n会計基準    : %s\\n%s\\n\" %\n",
    "                          ('-'*60, accounting_standard, '-'*60))\n",
    "\n",
    "            # コンテキストの種類ごとに\n",
    "            for idx, context_name in enumerate(context_names):\n",
    "                if len(stats[idx]) == 0:\n",
    "                    continue\n",
    "\n",
    "                # コンテキストごとの出現頻度のJSON\n",
    "                context_json = {}\n",
    "                accounting_json[context_name] = context_json\n",
    "\n",
    "                stats_f.write(\"\\n%s\\nコンテキスト: %s\\n%s\\n\" % (\n",
    "                    '-'*40, context_display_name(context_name), '-'*40))\n",
    "                v = list(sorted(stats[idx].items(),\n",
    "                         key=lambda x: x[1], reverse=True))\n",
    "\n",
    "                # 項目ごとに\n",
    "                for id, cnt in v:\n",
    "\n",
    "                    # 名前空間とタグ名を得る。\n",
    "                    ns, tag_name = id.split(':')\n",
    "\n",
    "                    # 名前空間に対応するスキーマの辞書を得る。\n",
    "                    assert ns in ns_xsd_dic\n",
    "                    xsd_dic = ns_xsd_dic[ns]\n",
    "\n",
    "                    # タグ名に対応する要素を得る。\n",
    "                    assert tag_name in xsd_dic\n",
    "                    ele = xsd_dic[tag_name]\n",
    "\n",
    "                    name = '\"%s\", # %s | %s | %s' % (\n",
    "                        id, ele.label, ele.verbose_label, ele.type)\n",
    "\n",
    "                    stats_f.write(\"\\t%s | %d\\n\" % (name, cnt))\n",
    "\n",
    "                    # 出現頻度, ラベル, 冗長ラベル, 型をJSONに保存する。\n",
    "                    context_json[id] = [cnt, ele.label,\n",
    "                                        ele.verbose_label, ele.type]\n",
    "\n",
    "                stats_f.write(\"\\n\")\n",
    "\n",
    "            stats_f.write(\"\\n\")\n",
    "\n",
    "    stats_f.close()\n",
    "\n",
    "    # 出現頻度をJSONファイルに書く。\n",
    "    with codecs.open('%s/stats.json' % data_path, 'w', 'utf-8') as f:\n",
    "        json.dump(stats_json, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    write_calc_tree(context_names, ns_xsd_dic,\n",
    "                    annual_account_stats, quarterly_account_stats)\n",
    "\n",
    "\n",
    "def concatenate_summary(cpu_count: int):\n",
    "    \"\"\"サブプロセスで作ったCSVファイルを１つにまとめる。\n",
    "\n",
    "    Args:\n",
    "        cpu_count(int): CPU数\n",
    "    \"\"\"\n",
    "    # ３つのコンテストのタイプに対し\n",
    "    for context_type in range(3):\n",
    "        summary_all = []\n",
    "        for cpu_id in range(cpu_count):\n",
    "            summary_path = \"%s/summary-%d-%d.csv\" % (\n",
    "                data_path, context_type, cpu_id)\n",
    "            lines = read_lines(summary_path)\n",
    "            if cpu_id != 0:\n",
    "                lines = lines[1:]\n",
    "            summary_all.extend(lines)\n",
    "\n",
    "            os.remove(summary_path)\n",
    "\n",
    "        with codecs.open(\"%s/summary-%d.csv\" % (data_path, context_type), 'w', 'utf-8') as f:\n",
    "            f.write('\\n'.join(summary_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDINETタクソノミの読み込み中・・・ : jpcrp_cor\n",
      "EDINETタクソノミの読み込み中・・・ : jppfs_cor\n",
      "EDINETタクソノミの読み込み中・・・ : jpdei_cor\n",
      "EDINETタクソノミの読み込み中・・・ : jpigp_cor\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ca62ac7b835c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprocess_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# すべてのサブプロセスが終了するのを待つ。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_spawn_posix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mForkServerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mfds_to_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "args = sys.argv\n",
    "if len(args) == 2:\n",
    "    assert args[1] == 'fix'\n",
    "\n",
    "    # 出力する項目がxbrl_table.pyの値で固定の場合\n",
    "    fixed_ids = True\n",
    "else:\n",
    "\n",
    "    # 前回の実行で作った出現頻度のJSONファイルを使い、出現頻度の高い項目を出力する場合\n",
    "    fixed_ids = False\n",
    "\n",
    "    # 出現頻度のJSONファイルを読む。\n",
    "    read_stats_json()\n",
    "'''\n",
    "fixed_ids = True\n",
    "# スキーマと名称リンクと計算リンクのファイルを読む。\n",
    "ReadAllSchema()\n",
    "\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "process_list = []\n",
    "\n",
    "# CPUごとにサブプロセスを作って並列処理をする。\n",
    "for cpu_id in range(cpu_count):\n",
    "\n",
    "    p = Process(target=make_summary, args=(fixed_ids, cpu_count, cpu_id,\n",
    "                ns_xsd_dic, verbose_label_dic, all_account_ids, filing_date_account_ids))\n",
    "\n",
    "    process_list.append(p)\n",
    "\n",
    "    p.start()\n",
    "\n",
    "# すべてのサブプロセスが終了するのを待つ。\n",
    "for p in process_list:\n",
    "    p.join()\n",
    "\n",
    "concatenate_summary(cpu_count)\n",
    "\n",
    "concatenate_stats(cpu_count)\n",
    "\n",
    "print('処理を終了しました。  処理時間:%d秒' % int(time.time() - start_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
