{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "import codecs\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "from xbrl_reader import read_company_dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/soichiro/Google Drive/sandbox/sandbox/data/EDINET/EdinetcodeDlInfo.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ee521ea7d05e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 会社情報の辞書を得る。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mcompany_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_company_dic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Google Drive/sandbox/sandbox/notebook/xbrl_reader.py\u001b[0m in \u001b[0;36mread_company_dic\u001b[0;34m()\u001b[0m\n\u001b[1;32m    403\u001b[0m     \"\"\"\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     lines = read_csv_file(\n\u001b[0m\u001b[1;32m    406\u001b[0m         root_dir + '/data/EDINET/EdinetcodeDlInfo.csv', 'shift_jis')\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/sandbox/sandbox/notebook/xbrl_reader.py\u001b[0m in \u001b[0;36mread_csv_file\u001b[0;34m(file_name, encoding)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_csv_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.8/Frameworks/Python.framework/Versions/3.9/lib/python3.9/codecs.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;31m# Force opening of the file in binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/soichiro/Google Drive/sandbox/sandbox/data/EDINET/EdinetcodeDlInfo.csv'"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.dirname(os.path.dirname(\n",
    "#   os.path.abspath(__file__))).replace('\\\\', '/')\n",
    "    os.path.abspath('EDINET.ipynb'))).replace('\\\\', '/')\n",
    "download_path = root_dir + '/zip/download'\n",
    "data_path = root_dir + '/python/data'\n",
    "\n",
    "for path in [data_path, download_path]:\n",
    "    if not os.path.exists(path):\n",
    "        # フォルダーがなければ作る。\n",
    "\n",
    "        os.makedirs(path)\n",
    "\n",
    "# 会社情報の辞書を得る。\n",
    "company_dic = read_company_dic()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def receive_edinet_doc_list(day_path: str, yyyymmdd: str):\n",
    "    \"\"\"EDINETから書類一覧APIを使って書類一覧が入ったJSONオブジェクト取得して返す。\n",
    "        Args:\n",
    "            day_path (str): JSONオブジェクトを保存するフォルダーのパス\n",
    "            yyyymmdd (str): 日付の文字列\n",
    "        Returns:\n",
    "            書類一覧が入ったJSONオブジェクト\n",
    "    \"\"\"\n",
    "    # 書類一覧APIのリクエストを送る。\n",
    "    url = 'https://disclosure.edinet-fsa.go.jp/api/v1/documents.json?date=%s&type=2' % yyyymmdd\n",
    "    req = urllib.request.Request(url)\n",
    "    with urllib.request.urlopen(req) as res:\n",
    "        try:\n",
    "            body = json.load(res)\n",
    "        except json.decoder.JSONDecodeError:\n",
    "            print(\"書類一覧のデータが不正です。\\nEDINETがメンテナンス中の可能性があります。\")\n",
    "            sys.exit()\n",
    "\n",
    "    if body['metadata']['status'] == \"404\":\n",
    "        # 書類がない場合\n",
    "\n",
    "        print(\"報告書の取得を終了しました。\")\n",
    "        return None\n",
    "\n",
    "    assert body['metadata']['message'] == \"OK\"\n",
    "\n",
    "    # JSONをファイルに書く。\n",
    "    json_path = \"%s/docs.json\" % day_path\n",
    "    with codecs.open(json_path, 'w', 'utf-8') as json_f:\n",
    "        json.dump(body, json_f, ensure_ascii=False)\n",
    "\n",
    "    return body\n",
    "\n",
    "\n",
    "def check_zip_file(zip_path: str):\n",
    "    \"\"\"ZIPファイルが壊れていないか調べる。\n",
    "    Args:\n",
    "        zip_path(str): ZIPファイルのパス\n",
    "    Returns:\n",
    "        bool: 壊れていなければTrue\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ZIPファイルを開いて壊れていないか調べる。\n",
    "        with zipfile.ZipFile(zip_path) as zf:\n",
    "            file_list = list(zf.namelist())\n",
    "\n",
    "        return True\n",
    "    except zipfile.BadZipFile:\n",
    "        return False\n",
    "\n",
    "\n",
    "def receive_edinet_doc(doc, dst_path):\n",
    "    \"\"\"EDINETから書類取得APIで決算情報のZIPファイルをダウンロードする。\n",
    "    Args:\n",
    "        doc          : 書類オブジェクト\n",
    "        dst_path(str): ダウンロード先のパス\n",
    "    \"\"\"\n",
    "    edinetCode = doc['edinetCode']\n",
    "    company = company_dic[edinetCode]\n",
    "\n",
    "    # 提出日時、提出者名、提出書類概要、業種を画面表示する。\n",
    "    print(\"%s | %s | %s | %s\" % (\n",
    "        doc['submitDateTime'], doc['filerName'], doc['docDescription'], company['category_name_jp']))\n",
    "\n",
    "    # 書類取得APIのリクエストを送る。\n",
    "    url = \"https://disclosure.edinet-fsa.go.jp/api/v1/documents/%s?type=1\" % doc['docID']\n",
    "    with urllib.request.urlopen(url) as web_file:\n",
    "        data = web_file.read()\n",
    "\n",
    "        # 決算情報のZIPファイルに書く。\n",
    "        with open(dst_path, mode='wb') as local_file:\n",
    "            local_file.write(data)\n",
    "\n",
    "        if not check_zip_file(dst_path):\n",
    "            # ZIPファイルが壊れている場合\n",
    "\n",
    "            print(\"!!!!!!!!!! ERROR !!!!!!!!!!\\n\" * 1)\n",
    "            print(\"msg:[%s] status:[%s] reason:[%s]\" % (\n",
    "                str(web_file.msg), str(web_file.status), str(web_file.reason)))\n",
    "            print(\"!!!!!!!!!! ERROR [%s] !!!!!!!!!!\\n\" % dst_path)\n",
    "            print(json.dumps(doc, indent=2, ensure_ascii=False))\n",
    "            print(\"!!!!!!!!!! ERROR !!!!!!!!!!\\n\" * 1)\n",
    "\n",
    "            os.remove(dst_path)\n",
    "            time.sleep(2)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "def select_doc(day_path, body):\n",
    "    \"\"\"書類一覧の中で対象となる書類を返す。\n",
    "    対象となる書類とは以下の条件を満たす書類。  \n",
    "    * 有価証券報告書/四半期報告書/半期報告書またはそれの訂正書類。\n",
    "    * 財務局職員が修正した書類ではない。  \n",
    "    * 会社情報の一覧に含まれる上場企業の書類\n",
    "    Returns:\n",
    "        対象書類\n",
    "    \"\"\"\n",
    "    for doc in body['results']:\n",
    "        docTypeCode = doc['docTypeCode']\n",
    "        if docTypeCode in ['120', '130', '140', '150', '160', '170'] and doc['docInfoEditStatus'] == \"0\":\n",
    "            # 有価証券報告書/四半期報告書/半期報告書またはそれの訂正書類で、財務局職員が修正したのではない場合\n",
    "\n",
    "            edinetCode = doc['edinetCode']\n",
    "            if edinetCode in company_dic:\n",
    "                # 会社情報の一覧に含まれる場合\n",
    "\n",
    "                company = company_dic[edinetCode]\n",
    "                if company['listing'] == '上場':\n",
    "                    # 上場企業の場合\n",
    "\n",
    "                    yield doc\n",
    "\n",
    "\n",
    "def get_xbrl_docs():\n",
    "    \"\"\"ダウンロードのメイン処理\n",
    "    現在の日付から１日ずつ過去にさかのぼって書類をダウンロードする。\n",
    "    \"\"\"\n",
    "\n",
    "    # 現在の日付\n",
    "    dt1 = datetime.datetime.today()\n",
    "\n",
    "    while True:\n",
    "        # １日過去にさかのぼる。\n",
    "        dt1 = dt1 + datetime.timedelta(days=-1)\n",
    "\n",
    "        yyyymmdd = \"%d-%02d-%02d\" % (dt1.year, dt1.month, dt1.day)\n",
    "        print(yyyymmdd)\n",
    "\n",
    "        day_path = \"%s/%d/%02d/%02d\" % (download_path,\n",
    "                                        dt1.year, dt1.month, dt1.day)\n",
    "        if not os.path.exists(day_path):\n",
    "            # フォルダーがなければ作る。\n",
    "\n",
    "            os.makedirs(day_path)\n",
    "\n",
    "        os.chdir(day_path)\n",
    "\n",
    "        json_path = \"%s/docs.json\" % day_path\n",
    "        if os.path.exists(json_path):\n",
    "            # 書類一覧のJSONファイルがすでにある場合\n",
    "\n",
    "            with codecs.open(json_path, 'r', 'utf-8') as f:\n",
    "                body = json.load(f)\n",
    "\n",
    "        else:\n",
    "            # 書類一覧のJSONファイルがない場合\n",
    "\n",
    "            body = receive_edinet_doc_list(day_path, yyyymmdd)\n",
    "            if body is None:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "\n",
    "        for doc in select_doc(day_path, body):\n",
    "            dst_path = \"%s/%s-%s-%d.zip\" % (\n",
    "                day_path, doc['edinetCode'], doc['docTypeCode'], doc['seqNumber'])\n",
    "            if os.path.exists(dst_path):\n",
    "                # すでに決算情報のZIPファイルがある場合\n",
    "\n",
    "                if check_zip_file(dst_path):\n",
    "                    # ZIPファイルが壊れていない場合\n",
    "\n",
    "                    continue\n",
    "\n",
    "                # 壊れているZIPファイルは削除する。\n",
    "                os.remove(dst_path)\n",
    "\n",
    "            # EDINETから決算情報のZIPファイルをダウンロードする。\n",
    "            receive_edinet_doc(doc, dst_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_xbrl_docs()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
